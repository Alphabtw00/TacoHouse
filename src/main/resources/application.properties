#H-2 DB CONFIG:--
spring.datasource.generate-unique-name=false
spring.datasource.name=tacohouse

#JPA CONFIG:--
#creates schema everytime app is started
spring.jpa.hibernate.ddl-auto=create
spring.jpa.show-sql=true

#ACTUATOR CONFIG:--
#to see all actuator endpoints
management.endpoints.web.exposure.include=*

#ADMIN SERVER CONFIG:--
#confugire client to admin server running on port 9090
spring.boot.admin.client.url=http://localhost:9090
#user and password to send to admin server(we secure the actuator) (use environment variable)
spring.boot.admin.client.username=${TACOHOUSE_USERNAME}
spring.boot.admin.client.password=${TACOHOUSE_PASSWORD}

#CLASS CONFIG
#admin password and username(AddAdminUser class) (use environment variable)
admin.username=${TACOHOUSE_USERNAME}
admin.password=${TACOHOUSE_PASSWORD}


#KAFKA CONFIG:--
#connect to kafka broker running at that port(9092) in our localhost (localhost:9092 by default)
spring.cloud.stream.kafka.binder.brokers= localhost:9092

#KAFKA OUTPUT
#adding a new output binder which is made at application initialization
spring.cloud.stream.output-bindings=contact
#binding our function(contact)(output channel) to kafka topic
spring.cloud.stream.bindings.contact.destination=tacohouse

#KAFKA INPUT
#to add consumer as a function to tell spring cloud stream
spring.cloud.function.definition=consumer
#binding our function(consumer)(input channel) to kafka topic
spring.cloud.stream.bindings.consumer-in-0.destination=tacohouse


